{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import some libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "import seaborn as sb\n",
    "sb.set_style('darkgrid')\n",
    "rcParams['figure.figsize'] = 8,8\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "train = pd.read_csv('Train.csv')\n",
    "test=  pd.read_csv('Test.csv')\n",
    "submission = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the data types in the train data\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check how many levels are involved in each of the categorical features (object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['REGION'].value_counts())\n",
    "plt.figure(figsize=(10,5))\n",
    "train['REGION'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('REGION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['TENURE'].value_counts())\n",
    "plt.figure(figsize=(10,5))\n",
    "train['TENURE'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('TENURE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['MRG'].value_counts())\n",
    "plt.figure(figsize=(10,5))\n",
    "train['MRG'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('MRG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probaly not the best way to visualize this\n",
    "print(train['TOP_PACK'].value_counts())\n",
    "plt.figure(figsize=(10,5))\n",
    "train['TOP_PACK'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('TOP_PACK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the predictor class is balanced \n",
    "print(train['CHURN'].value_counts())\n",
    "plt.figure(figsize=(10,5))\n",
    "train['CHURN'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('Churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check summary of numerical fields\n",
    "train.select_dtypes(include=['int64', 'float64']).describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values in training data\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for missing values in test data\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will drop REGION, TOP_PACK, and MRG\n",
    "#We will also replace the missing values for the numerical columns with their means (averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=['TOP_PACK'], inplace=True) #drop these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns=['TOP_PACK'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill NAs for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['MONTANT'].fillna((train['MONTANT'].mean()), inplace=True)\n",
    "train['FREQUENCE_RECH'].fillna((train['FREQUENCE_RECH'].mean()), inplace=True)\n",
    "train['REVENUE'].fillna((train['REVENUE'].mean()), inplace=True)\n",
    "train['ARPU_SEGMENT'].fillna((train['ARPU_SEGMENT'].mean()), inplace=True)\n",
    "train['FREQUENCE'].fillna((train['FREQUENCE'].mean()), inplace=True)\n",
    "train['DATA_VOLUME'].fillna((train['DATA_VOLUME'].mean()), inplace=True)\n",
    "train['ON_NET'].fillna((train['ON_NET'].mean()), inplace=True)\n",
    "train['ORANGE'].fillna((train['ORANGE'].mean()), inplace=True)\n",
    "train['TIGO'].fillna((train['TIGO'].mean()), inplace=True)\n",
    "train['ZONE1'].fillna((train['ZONE1'].mean()), inplace=True)\n",
    "train['ZONE2'].fillna((train['ZONE2'].mean()), inplace=True)\n",
    "train['FREQ_TOP_PACK'].fillna((train['FREQ_TOP_PACK'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill NAs for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['MONTANT'].fillna((test['MONTANT'].mean()), inplace=True)\n",
    "test['FREQUENCE_RECH'].fillna((test['FREQUENCE_RECH'].mean()), inplace=True)\n",
    "test['REVENUE'].fillna((test['REVENUE'].mean()), inplace=True)\n",
    "test['ARPU_SEGMENT'].fillna((test['ARPU_SEGMENT'].mean()), inplace=True)\n",
    "test['FREQUENCE'].fillna((test['FREQUENCE'].mean()), inplace=True)\n",
    "test['DATA_VOLUME'].fillna((test['DATA_VOLUME'].mean()), inplace=True)\n",
    "test['ON_NET'].fillna((test['ON_NET'].mean()), inplace=True)\n",
    "test['ORANGE'].fillna((test['ORANGE'].mean()), inplace=True)\n",
    "test['TIGO'].fillna((test['TIGO'].mean()), inplace=True)\n",
    "test['ZONE1'].fillna((test['ZONE1'].mean()), inplace=True)\n",
    "test['ZONE2'].fillna((test['ZONE2'].mean()), inplace=True)\n",
    "test['FREQ_TOP_PACK'].fillna((test['FREQ_TOP_PACK'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,recall_score,precision_recall_curve, f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropcols = ['user_id', 'CHURN', 'MRG', 'REGION']\n",
    "y = train['CHURN']\n",
    "x = train.drop(columns=dropcols, axis=1)\n",
    "test = test.drop(columns=['user_id'], axis=1) #you will use this for predicting and submitting the resulting\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training data into train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.5,random_state=5)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Further split X_train and y_train into train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size = 0.3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train\")\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(\"+\"*7)\n",
    "print(\"test\")\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(\"+\"*7)\n",
    "print(\"validation\")\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['MONTANT', 'FREQUENCE_RECH', 'REVENUE', 'ARPU_SEGMENT', 'FREQUENCE',\n",
    "       'DATA_VOLUME', 'ON_NET', 'ORANGE', 'TIGO', 'ZONE1', 'ZONE2',\n",
    "       'REGULARITY', 'FREQ_TOP_PACK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[num_cols] = scaler.fit_transform(X_train[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[num_cols] = scaler.transform(X_test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[num_cols] = scaler.transform(test[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val[num_cols] = scaler.transform(X_val[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the TENURE column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "X_train[\"TENURE\"] = encoder.fit_transform(X_train[\"TENURE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"TENURE\"] = encoder.transform(X_test[\"TENURE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val['TENURE'] = encoder.transform(X_val[\"TENURE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['TENURE'] = encoder.transform(test[\"TENURE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##RandomForestClassifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rand = RandomForestClassifier(bootstrap=True,criterion = \"gini\", n_jobs=-1, max_depth=7, n_estimators=200, random_state=1, verbose=True)\n",
    "inputs = tf.keras.Input(shape=(14)) #15\n",
    "x1 = tf.keras.layers.Dense(160, activation='relu')(inputs)\n",
    "x2 = tf.keras.layers.Dense(160, activation='relu')(x1)\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x2)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=[tf.keras.metrics.AUC(name='auc')])\n",
    "\n",
    "\n",
    "batch_size = 300\n",
    "epochs = 10\n",
    "\n",
    "\n",
    "\n",
    "#Fit model on data\n",
    "#randmodel = rand.fit(X_train,y_train)\n",
    "\n",
    "history = model.fit(X_train, y_train,validation_split=0.2,batch_size=batch_size,epochs=epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on the X_test data \n",
    "#randpred = randmodel.predict(X_test)\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Acuracy\")\n",
    "#accuracy_score(y_test, randpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Recall\")\n",
    "#recall_score(y_test, randpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"F1 Score\")\n",
    "#f1_score(y_test, randpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion_matrix(y_test, randpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"CHURN\"] = subpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.to_csv('submission_A.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Do more feature engineering\n",
    "# 2. Handle the imbalance nature of the predictor class \n",
    "# 3. Use other algorithms\n",
    "# 4. Tune hyperparameters of this model\n",
    "# 5. Handle missing values properly\n",
    "# 6. Any other thing you feel can improve the performance of the model is good to go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Good Luck !!!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e922dd073470bdcc017ae3abd31d6491d6ed7bf31c1d559806e5511bfea88b81"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
